{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a6874b-3d38-4493-8b5a-7374f4e8a4fc",
   "metadata": {},
   "source": [
    "# 25th april assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38776d0c-7000-4d3f-9ca6-c218f09c674a",
   "metadata": {},
   "source": [
    "Ques1. What are eigen values and eigen vectors? How are they related\n",
    "to the eigen-decomposition approach? Explain with an example.\n",
    "\n",
    "ans\n",
    "\n",
    "Eigen values and Eigen vectors are concepts in linear algebra that play\n",
    "a key role in many data analysis and machine learning algorithms. In the\n",
    "context of matrices, an Eigen vector of a square matrix A is non-\n",
    "zero vector v such that when  A is multiplied by V, the result is a scalar\n",
    "multiple of v. This scalar multiple is known as Eigen  value associated\n",
    "with the Eigen vector v. mathematically , this relationship can be \n",
    "expressed as :\n",
    "    AV = λv, where λ is the Eigenvalue.\n",
    "    \n",
    "Eigen - decomposition is an approach that involves decomposing a square matrix into its eigen vector\n",
    "and eigen values. Specifically, if A is a square matrix, then its eigen-decomposition is given by : A  = PDP^-1, where P is a matrix whose columns are the eigen vectors of A , and D is a diagonal matrix whose entries are the corresponding eigen values. \n",
    "\n",
    "As an example, consider the following  2*2 matrix\n",
    "\n",
    "A = [ 2 1 ]\n",
    "    [ 1 2 ]\n",
    "The characteristic polynomial of this matrix is given by: λ^2 - 4λ + 3, which has roots at λ = 1 and λ = 3. These are the Eigenvalues of matrix A. The corresponding Eigenvectors can be found by solving the equation (A - λI)v = 0 for each Eigenvalue. For λ = 1, we have:\n",
    "\n",
    "[ 2 1 ]   [ 1 ]   [ 1 ]   [ 0 ]\n",
    "[ 1 2 ] - [   ] = [   ] * v = [   ]\n",
    "          [ 0 ]   [ 1 ]   [ 0 ]\n",
    "\n",
    "Solving this system of equations gives us the Eigenvector [1, -1] associated with the Eigenvalue λ = 1. Similarly, for λ = 3, we have:\n",
    "\n",
    "[ 2 1 ]   [ 3 ]   [ -1 ]   [ 0 ]\n",
    "[ 1 2 ] - [   ] = [    ] * v = [   ]\n",
    "          [ 0 ]   [ -1 ]   [ 0 ]\n",
    "\n",
    "Solving this system of equations gives us the Eigenvector [1, 1] associated with the Eigenvalue λ = 3. Therefore, the Eigen-decomposition of matrix A is given by:\n",
    "\n",
    "A = PDP^-1\n",
    "    where P = [ 1 -1 ]\n",
    "              [     ]\n",
    "              [ 1 -1 ]\n",
    "          D = [3]\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "\n",
    "Eigenvalues and Eigenvectors are concepts in linear algebra that describe how a square matrix can stretch or compress vectors along certain directions. Eigen-decomposition is an approach that involves decomposing a \n",
    "square matrix into its Eigenvectors and Eigenvalues. This can be useful for understanding the properties of the matrix and for performing various data analysis and machine learning tasks.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f5df76-737b-4a30-9c36-13098480e2b7",
   "metadata": {},
   "source": [
    "Ques2. What is eigen decomposition and what is its significance in linear \n",
    "algebra ?\n",
    "\n",
    "ans\n",
    "\n",
    "Eigen - decomposition , also known as spectral decomposition , is a form \n",
    "of matrix decomposition. It involves decomposing a square matrix into a set\n",
    "of eigen vectors and eigen values.\n",
    "\n",
    "A square matrix A can  be decomposed as A = PDP^-1 , where : \n",
    "    - P is a matrix whose columns are eigen vectors of A.\n",
    "    - D is a diagonal matrix whose entries are eigen values of A.\n",
    "    - P^-1 is the inverse of the matrix P. \n",
    "    \n",
    "    The significance of eigen -decomposition in linear algebra and many\n",
    "    other fields like data analysis, physics , and engineering is profound. \n",
    "    Here are some key points:\n",
    "        \n",
    "        \n",
    "1. **Diagonalization** Eigen decomposition allows a matrix to be diagonlized,\n",
    "    which simplifies various matrix operations. When a matrix  is diagonal, raising it \n",
    "    to a power, computing exponentials, and taking roots become much easier.\n",
    "    \n",
    "2. **understanding Transformations** : Eigen values and eigen vectors provide insights\n",
    "     into the behaviour of linear transformations represented by matrices. They\n",
    "        help in understanding how matrix stretches or compresses space along \n",
    "        specific directions.\n",
    "3.**Principal component analysis(PCA)**: Eigen decomposition plays a crucial role in PCA, a dimensionality reduction technique widely used in data analysis and machine learning. PCA finds the principal components(eigen vectors) of a dataset to reduce its dimensionality while preserving the most important information.\n",
    "\n",
    "\n",
    "4. **Differential Equations** : Eigen decomposition is used in solving systems of linear differential equations, which arise in various fields, including physics and engineering.\n",
    "\n",
    "5. **Spectral Decomposition:** Eigen decomposition is related to spectral decomposition, which helps in understanding the spectral properties of matrices and is used in various applications, such as graph theory and quantum mechnics.\n",
    "\n",
    "6. **Stability Analysis**  : In fields like control theory, eigen decomposition is used  to analyze the stability of systems by examining the eigen values of matrices that describe system dynamics.\n",
    "        \n",
    "        \n",
    " \n",
    " Conclusion: Eigen decomposition is a powerful tool in linear algebra that provides insights into matrix transformations, simplifies calculations , and finds applications in various scienific and engineering disciplines. It is a fundamental concept for understanding the behavior of linear systems and matrices.\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2672a9-60ce-4266-b6ce-14d6124d95a9",
   "metadata": {},
   "source": [
    "What are the conditions that must be satisfied for a square matrix to be diagonalizable using the\n",
    "Eigen-Decomposition approach? Provide a brief proof to support your answer.\n",
    "\n",
    "ans\n",
    "\n",
    "A square matrix can be diagonalizable using the eigen -decomposition approach if and only if it satisfies  the following conditions : \n",
    "\n",
    "1. The matrix must be square : The matrix must have the same number of rows and columns.\n",
    "\n",
    "2. The matrix must have n linearly independent eigen vectors :\n",
    "for n*n matrix A,\n",
    "it must have n linearly independent eigen vectors corresponding to its eigen values.\n",
    "\n",
    "\n",
    "Here's a brief proof to support this statement:\n",
    "\n",
    "Let A be an n x n matrix. Suppose that A has n linearly independent eigenvectors v1, v2, ..., vn, with corresponding eigenvalues λ1, λ2, ..., λn. Let P be the matrix whose columns are the eigenvectors of A, and let D be the diagonal matrix whose entries are the eigenvalues of A. Then, by definition of eigenvectors and eigenvalues, we have:\n",
    "\n",
    "AP = [Av1 Av2 ... Avn]\n",
    "   = [λ1v1 λ2v2 ... λnvn]\n",
    "   = PD\n",
    "Since the columns of P are linearly independent, it follows that P is invertible. Multiplying both sides of the above equation by P^-1, we obtain:\n",
    "\n",
    "APP^-1 = PDP^-1\n",
    "      => A = PDP^-1\n",
    "Thus, if a matrix has n linearly independent eigenvectors, it can be diagonalized using the Eigen-Decomposition approach.\n",
    "\n",
    "Conversely, suppose that a matrix A can be diagonalized as A = PDP^-1. Then the columns of P are eigenvectors of A, and since P is invertible, its columns must be linearly independent. Thus, if a matrix is diagonalizable, it must have n linearly independent eigenvectors.\n",
    "\n",
    "In summary, a square matrix is diagonalizable using the Eigen-Decomposition approach if and only if it has enough linearly independent eigenvectors to form a complete basis for its column space. This result follows from the definition of eigenvectors and eigenvalues and the properties of invertible matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815a8821-7340-4808-931e-d2897c03e620",
   "metadata": {},
   "source": [
    "Ques4. What is the significance of the spectral theorem in the context of the\n",
    "Eigen-decomposition  approach? How is it related to the diagonalizability\n",
    "of a matrix? Explain with an examples.\n",
    "\n",
    "ans\n",
    "\n",
    "The spectral theorem is a result in linear algebra and functional \n",
    "analyis that provides conditions under which a linear operator or matrix\n",
    "can be diagonalized, i.e., represented as a diagonal matrix in some basis. This \n",
    "is extremely useful because computations involving a diagonalizable \n",
    "matrix can be reduced to much simpler computations involving the corresponding \n",
    "diagonal matrix.\n",
    "\n",
    "In the context of the Eigen-Decomposition  approach , the spectral theorem\n",
    "is significant because it identifies a class of linear operators that can be modeled by multiplication operators, which are as simple as one can hope to find. The spectral theorem also  provides a canonical decomposition, called the spectral decomposition, of the underlying vector space on which the operator acts.\n",
    "\n",
    "\n",
    "For example, let's consider a real symmetric matrixA. According to the spectral theorem , A is orthogonally diagonalizable. This means that there exists an orthogonoal matrix P such that P^TAP = D , where  D is a diagonal matrix. The columns of P are eigen vectors of A, and the entries of D are the corresponding eigen values. This is called the eigen -decomposition of A. \n",
    "\n",
    "Conclusion : the spectral theorem provides conditions under which a matrix can be diagonalized,and this is useful in the context of the eigen -decomposition approach because it allows us to represent a matrix as a diagonal matrix in some basis, which simplifies computations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace19fba-9e40-49e1-8804-9376bb67d0b6",
   "metadata": {},
   "source": [
    "Ques 5. How do you find the eigen values of a matrix and what do they represent?\n",
    "\n",
    "ans\n",
    "\n",
    "The eigen values of a matrix are scalars that are associated with a linear transformation of a vector space. They represent the factor by which an eigen vector is streteched when the matrix is applied to it. In other words, if A  is a square matrix and v is a vector, then λ is a scalar quantity represented as Av = λv, where λ is considered to be the eigenvalue of matrix A.\n",
    "\n",
    "To find the eigen values of a matrix, you can follow these steps: \n",
    "\n",
    "1. Make sure the given matrix A  is a square matrix. Also, determine the identity matrix I of the same  order.\n",
    "\n",
    "2. Estimate the matrix A- λI, where  λ is a scalar quantity.\n",
    "3. Find the determinant of matrix A- λI  and equate it to zero.\n",
    "\n",
    "4. From the equation thus obtained , calculate all the possible \n",
    "values of  λ , which are the required eigen values of matrix A.\n",
    "\n",
    "The computation of eigen values and eigen vectors for a square matrix is known as eigen value deccomposition. The eigen values so obtained are usually denoted by   λ1, λ2, ….. or e1, e2, …."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491c48b2-0a4a-46ff-8976-541621f23635",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques 6. What are eigen vectors and how are they related to eigen values?\n",
    "\n",
    "ans\n",
    "\n",
    "An eigen vector is a non-zero vector that changes at most by a constant factor\n",
    "when a linear transformation is applied to it. The corresponding eigen\n",
    "value, often  represented by λ,  is the multiplying factor. Geometrically,\n",
    "a transformation matrix rotates, stretches , or shears the vectors it acts\n",
    "upon. The eigen vectors for a linear transformation matrix are the set of \n",
    "the vectors that are only stretched , with no rotation or shear. The\n",
    "eigen value is the factor by which an eigen vector is stretched . If the \n",
    "eigen value is negative, the direction is reversed.\n",
    "\n",
    "In other words, if A is a square matrix and v is a vector , then λ, isa \n",
    "scalar quantity represented as AV = λV, where λ is considered to\n",
    "be the eigen value of matrix A  and V is the eigen vector. Eigen vectors and \n",
    "eigen values  have a wide range of applications, for example in stability analysis\n",
    ", vibratin analyis, atomic orbitals , facial recognition, and matrix \n",
    "diagonalizaition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f16a8-12d1-473c-9468-96fe114cd8e4",
   "metadata": {},
   "source": [
    "Ques 7. Can you explain the geometri interpretation of eigen\n",
    "vectors and eigen values?\n",
    "\n",
    "ans\n",
    "\n",
    "In geometirc terms, an eigen vector is a vector whose direction remains\n",
    "unchanged when a linear transforamtion is applied to it . When a matrix \n",
    "acts upon an eigen vector, the output is a scaled version of the original\n",
    "vector. This scaling factor is the eigen Value.\n",
    "\n",
    "\n",
    "for example , consider a transformation matrix that rotates , stretches\n",
    "or shears the vectors it acts upon. The eigen vectors for this matrix are \n",
    "the set of vectors that are only stretched, with no rotation  or shear.The\n",
    "eigen value is the factor by which an eigen vector is stretched . If the eigen\n",
    "values is negative, the direction of the eigen vector is reversed.\n",
    "This means that if A is a square matrix and v is an eigen vector of A , then\n",
    "then Av = λv, where λ is the eigenvalue associated with v. In other words, applying the transformation A to \n",
    "the vector v only scales v by the factor λ, without changing its direction (unless λ is negative).\n",
    "\n",
    "This geometric interpretation of eigen values and eigen vectors provides insight into the symmetry of a given operation . For instance, in rotation matrices, the centre of rotation(often  origin) , or axis of rotation for highere dimensional cases, are exmaples of vectors not changed  by the transformation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a54472-9172-4e4f-8da5-0afe18eae9ae",
   "metadata": {},
   "source": [
    "Ques8 . What are some real-world applications of eigen decomposition?\n",
    "\n",
    "ans\n",
    "\n",
    "Eigen decomposition has many real -world applications. Here are some \n",
    "examples:\n",
    "    \n",
    "**1.image compression**  Singular value decomposition , which is closely related  to eigen decomposition , can be used to compress images by throwing away small eigen values.\n",
    "    \n",
    "**2.Deriving  Special Relativity**  The language of linear algebra, including eigen values and eigen vectors , can be used to derive special realitivity. In fact, Einstein 's second postulates states that 'Light is an eigen vector of the Lorentz transform'.\n",
    "\n",
    "**3.Spectral Clustering** Eigen decomposition can be used in spectral clustering , which is a techniques used ot partition a dataset into clusters based on the similarity between data points.\n",
    "\n",
    "**4. System of first-order differential equations** Eigen values and eigen vectors can be used to solve system of first-order differential equations. \n",
    "\n",
    " \n",
    "**5. Google's pagerank algorithm** The well -known PageRank algorithm, used by google to rank web pages in their search engine results, is based on the concept of eigen vectors. \n",
    "\n",
    "These are just a few examples of the many real-world applications of eigen decompositioon . It is a powerful tool with wide range of uses in various fields.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e53244-8b74-4bc2-81e9-e1623c937c93",
   "metadata": {},
   "source": [
    "Ques 9. Can a matrix have more than one set of eigen vectors and eigen\n",
    "values?\n",
    "\n",
    "ans\n",
    "\n",
    "Yes, a matrix can have more than one set of eigen vectors and eigen values.\n",
    "Matrices can have more than one eigen vector sharing the same eigen \n",
    "value. The converse statement , that an eigen vector can have more than \n",
    "one eigen value,is not true, which you can see from the definition of an eigen vector. However, there's nothing in the definition that stops us from having multiple eigen vectors with the same eigen value.\n",
    "\n",
    "\n",
    "If a matrix has more than one eigen , the associated eigen vectors can be different for the different eigen vectors. Geometrically, the action of a matrix on one of its eigen vectors causes the vector to strech (or shrink) and /or reverse direction.\n",
    "\n",
    "If the eigen values are distinct , then there is only one set of unit size eigen vectors. If there  are duplicate eigen values, then  for these eigenvalues, the eigen vectors are not distinct (but any eigen vectors corresponding  to unique eigen values are still distinct).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a20388-c800-4142-ab30-3fc0564777cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques 10 . In what ways is the eigen -decomposition approach useful in data\n",
    "analysis and machine learning? Discuss at least three specific \n",
    "applications or techniques that rely on eigen decomposition.\n",
    "\n",
    "\n",
    "ans\n",
    "\n",
    "Eigen-decomposition is a powerful tool in data analysis and machine learing\n",
    ". Here are three specific application or techniques that relyon eigen-\n",
    "decomposition:\n",
    "    \n",
    "    1. **Principal Component Analysis(PCA) **: PCA is a technique used to \n",
    "    reduce the dimensionality of data by transforming the correlated features in the \n",
    "    data into linearly independent (orthogonal) components. This is done\n",
    "    by decomposing the covariance matrix of the data into its eigen vectors\n",
    "    and eigen values, and then projecting the data onto its eigen vectors\n",
    "    and eigen values. The eigen vectors with the largest eigen values captured\n",
    "    most of the variance in the data, and can be used to represent the data in \n",
    "    a lower dimensional space.\n",
    "    \n",
    "    2. ** Spectral Clustering** Spectral clustering is a technique used to \n",
    "    partition  a dataset into clusters based on the similarity between data points\n",
    "    . This is done by constructing a similarity matrix for the data, and\n",
    "    then  decomposing this matrix into its eigen vectors and eigen vlaues.\n",
    "    The eigen vectors corresponding to the smallest eigen values are then used\n",
    "    to represent the data in a lower-dimensioal space, where traditional clustering\n",
    "    algorithms can be applied.\n",
    "    \n",
    "    \n",
    "    .3 ** Latent Semantic Analysis(LSA)**  LSA is a technique used to analyze\n",
    "    relationship between a set of documents and the terms they contain.\n",
    "    This is done by constructing a term -document  matrix for the data, and \n",
    "    then decomposing this matrix into its eigen vectors  and eigen values.\n",
    "    The eigen vectors with the largest eigen values capture most of the \n",
    "    variance in the data, and can be used to represent the document in a lower-\n",
    "    dimensional space, where similarities between documents can be computed.\n",
    "    \n",
    "    \n",
    "    \n",
    "    These are just a few examples of how Eigen-decomposition is used in data\n",
    "    analysis and machine learning.It is powerful tool with many applications.\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23789c0c-92f9-49fb-99ed-6ff20437dfb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
